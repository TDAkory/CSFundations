# [HyperLogLog](https://en.wikipedia.org/wiki/HyperLogLog)

## 一、算法核心定位

**HyperLogLog（HLL）** 是由Philippe Flajolet等人于2007年提出的一种**近似基数计数算法**，核心目标是用极小的内存开销（空间复杂度仅为\(O(\log\log N)\)，N为数据集基数）估算大规模数据集的**基数（Cardinality，即不重复元素个数）** ；其原理基于“均匀分布哈希值的前导零长度统计”，通过分桶策略（通常划分为\(2^{10}=1024\)个桶）和调和平均降低误差，默认误差率约**2%** ，支持分布式场景下的结构合并，广泛应用于Redis、数据库（如PostgreSQL）的UV统计、日志去重等大规模数据计数场景，是“空间-精度”权衡的经典方案。

| 项目                | 关键内容                                                                 |
|---------------------|--------------------------------------------------------------------------|
| **算法名称**        | HyperLogLog（简称HLL）                                                  |
| **提出时间**        | 2007年                                                                   |
| **提出者**          | Philippe Flajolet、Éric Fusy、Olivier Gandouet、Frédéric Meunier          |
| **算法定位**        | 近似基数计数算法（估算数据集不重复元素个数）                             |
| **核心优势**        | 1. 空间开销极小：\(O(\log\log N)\)，1024个桶仅需1KB内存；2. 误差可控：默认约2%；3. 支持分布式合并 |
| **核心局限**        | 1. 仅近似计数，无法提供精确值；2. 不支持元素删除；3. 依赖高质量哈希函数（如MurmurHash） |

## 算法原理

### 基本原理

- **哈希均匀分布假设**：对数据集中每个元素应用64位哈希函数（如MurmurHash3、CityHash），得到均匀分布的二进制哈希值，确保每个bit为0或1的概率均为1/2。
- **前导零长度定义**：对任意元素的哈希值，定义\(ρ(x)\)为“从最低位开始连续的0的个数”，例如：
  - 哈希值`...0001`的\(ρ(x)=3\)；
  - 哈希值`...1`的\(ρ(x)=0\)；
- **概率关联**：数据集基数N越大，哈希值中“前导零长度较大”的元素越可能出现，例如N=10⁶时，大概率存在\(ρ(x)≥20\)的元素。

### 分桶优化（降低误差）

- **分桶策略**：将哈希值的前\(b\)位作为“桶索引”，剩余\(64-b\)位用于计算前导零长度\(ρ(x)\)，共划分\(m=2^b\)个桶（Wikipedia中典型取值为\(b=10\)，即\(m=1024\)个桶）。
- **桶内更新**：对每个元素，计算其桶索引\(i\)和\(ρ(x)\)，更新第\(i\)个桶的最大值\(M[i] = \max(M[i], ρ(x))\)（\(M[i]\)表示第\(i\)个桶中所有元素的最大前导零长度）。

### 基数估算公式

- **基础估算公式**：通过桶最大值的调和平均降低随机误差，公式如下：  
  \[
  \hat{n} = \alpha_m \cdot m \cdot \left( \sum_{i=0}^{m-1} \frac{1}{2^{M[i]}} \right)^{-1}
  \]  
  其中\(\alpha_m\)为**修正系数**，用于补偿哈希非理想分布和有限桶数的偏差，取值随桶数\(m\)变化：
  | 桶数\(m\) | 修正系数\(\alpha_m\) |
  |-----------|----------------------|
  | 16        | 0.673                |
  | 32        | 0.697                |
  | 64        | 0.709                |
  | ≥128      | 0.7213/(1+1.079/m)    |
- **小基数修正**：当估算值\(\hat{n} < 5m\)时，直接统计“未更新的桶数\(V_0\)（即\(M[i]=0\)的桶数）”，用以下公式修正，提升小数据集估算精度：  
  \[
  \hat{n} = m \cdot \log\left( \frac{m}{V_0} \right)
  \]
- **大基数截断**：当估算值超过哈希值位数对应的最大基数（如64位哈希的最大基数\(2^{64}\)）时，直接截断为最大值，避免溢出。

### 典型应用场景

| 场景领域       | 具体应用案例                                                                 | 核心优势体现                     |
|----------------|------------------------------------------------------------------------------|----------------------------------|
| 互联网UV统计   | 网站/APP的日活（DAU）、月活（MAU）统计，如1亿用户仅需1KB内存存储HLL结构       | 空间效率极高，降低服务器内存占用 |
| 数据库查询优化 | PostgreSQL、ClickHouse等数据库的`APPROX_COUNT_DISTINCT`函数，加速去重计数查询 | 避免全表扫描，提升查询性能       |
| 缓存系统       | Redis内置`PFADD`（插入元素）、`PFCOUNT`（估算基数）、`PFMERGE`（合并结构）命令 | 支持分布式计数，适配缓存场景     |
| 日志分析       | Nginx日志中独立IP、独立请求URL的计数，处理TB级日志数据                         | 处理大规模数据，无需存储原始数据 |

## 延伸问题

### 问题1：HyperLogLog算法为什么能实现“极小内存开销”？其空间复杂度\(O(\log\log N)\)是如何推导的？

**答案**：  
- 核心原因：HLL不存储原始元素，仅存储“分桶后的最大前导零长度”——每个桶仅需1个整数（通常4字节）记录最大值，桶数\(m=2^b\)（b为哈希值用于桶索引的位数），而b的取值仅需随\(\log\log N\)增长（例如N=10¹²时，b=12即可满足误差要求），因此总内存开销为\(O(m)=O(2^b)=O(\log\log N)\)。  
- 推导逻辑：假设数据集基数为N，哈希值前导零长度的最大值\(ρ_{max}\)满足\(2^{ρ_{max}} ≈ N\)（概率意义上），即\(ρ_{max} ≈ \log_2 N\)；分桶数m需与\(ρ_{max}\)成正比（确保误差可控），即\(m ∝ \log_2 N\)，但实际工程中m取\(2^b\)，b仅需\(\log_2(\log_2 N)\)（例如N=10¹²时，\(\log_2 N≈40\)，\(\log_2(\log_2 N)≈6\)，实际取b=10即可），因此空间复杂度最终为\(O(\log\log N)\)。

### 问题2：HyperLogLog的误差率如何控制？在实际工程中（如Redis），若需将误差率从2%降至1%，需如何调整参数？

**答案**：  
- 误差控制原理：HLL的误差主要来自“哈希分布偏差”和“分桶统计的随机波动”，通过两个机制控制：1. 分桶策略（增加桶数m，降低随机波动）；2. 修正系数\(\alpha_m\)（补偿哈希非均匀分布的偏差），理论误差率公式为\(\epsilon ≈ 1.04/\sqrt{m}\)。  
- 工程参数调整：  
  - 默认误差率2%：对应桶数\(m=1024\)（\(1.04/\sqrt{1024}≈1.04/32≈3.25\%\)，实际通过\(\alpha_m\)修正后约2%）；  
  - 误差率降至1%：根据\(\epsilon ≈ 1.04/\sqrt{m}\)，解得\(m≈(1.04/0.01)^2≈10816\)，取\(m=16384\)（\(2^{14}\)），此时\(1.04/\sqrt{16384}≈1.04/128≈0.81\%\)，满足1%误差要求；  
  - Redis中的实现：Redis默认使用m=1024（误差约2%），若需更低误差，需通过自定义参数调整桶数（需注意内存开销同步增加，m=16384时内存开销约16KB）。

### 问题3：HyperLogLog支持分布式场景的合并操作，其合并原理是什么？与其他分布式基数计数方案（如布隆过滤器+哈希表）相比，HLL的优势在哪里？

**答案**：  
- 合并原理：HLL的合并逻辑基于“逐桶取最大值”——两个HLL结构（需保证桶数m相同）合并时，对每个桶索引i，新桶的最大值\(M_{merged}[i] = \max(M_1[i], M_2[i])\)，合并后的结构可直接用于\(PFCOUNT\)估算总基数；该过程无需汇总原始数据，仅需传输HLL的桶数组（如m=1024时仅需1KB数据），适合分布式场景。  
- 与其他方案的优势对比：  
  | 对比维度       | HyperLogLog                | 布隆过滤器+哈希表            |
  |----------------|-----------------------------|-------------------------------|
  | 空间开销       | 极小（数KB）                | 较大（布隆过滤器+哈希表存储） |
  | 合并复杂度     | 低（逐桶取最大值，O(m)时间） | 高（需合并哈希表，O(N)时间） |
  | 误差特性       | 可控（2%/1%）               | 无误差（精确计数）            |
  | 适用场景       | 大规模近似计数（如UV）       | 小规模精确计数（如小数据集去重） |
  - 核心优势：HLL在“大规模分布式场景”下，空间开销和合并效率远优于布隆过滤器+哈希表，虽为近似计数，但误差可控，能满足绝大多数工程场景（如UV统计无需精确到个位数）的需求。

## 基于原始论文的数学推导

> HyperLogLog: the analysis of a near-optimal cardinality estimation algorithm
>
> 论文的核心贡献是通过“哈希概率特性+分桶调和平均”，在 \(O(\log\log N)\) 空间复杂度下实现基数的近似估算，推导过程围绕“概率建模→期望分析→方差优化→工程修正”展开。

在开始推导前，需明确论文中两个关键前提和核心定义，这是后续所有数学分析的基础：

### 1. 核心假设（论文 Section 1）

- **哈希均匀分布假设**：存在一个高质量哈希函数 \(h: D \to \{0,1\}^\infty\)，能将数据集中的任意元素映射为“无限长二进制串”，满足：
  1. 每个比特位取值为 0 或 1 的概率均为 \(\frac{1}{2}\)；
  2. 不同元素的哈希值相互独立（无碰撞，工程中用 32 位哈希即可支撑 \(10^9\) 以上基数的估算）。

### 2. 核心定义（论文 Section 1）

- **前导零长度 \(\rho(s)\)**：对任意哈希值 \(s\)，定义 \(\rho(s)\) 为“从最高位（MSB）开始，连续的 0 之后首次出现 1 的位置”。  
  示例：
  - 哈希值 \(s = 0001...\)（最高 4 位为 0001）→ \(\rho(s) = 4\)；
  - 哈希值 \(s = 1...\)（最高位为 1）→ \(\rho(s) = 1\)；
  - 哈希值 \(s = 0000...00\)（全 0）→ \(\rho(s) = \infty\)（工程中按哈希位数上限处理）。

该算法的核心目标：估算数据集的**基数 \(n\)**（不重复元素个数），无需存储所有元素，仅通过哈希值的 \(\rho(s)\) 特性间接推导。

### 步骤 1：单个元素的 \(\rho(s)\) 概率分布（论文 Section 2.1）

根据哈希均匀分布假设，计算任意元素的 \(\rho(s) = k\) 的概率：

- 要满足 \(\rho(s) = k\)，需同时满足两个条件：
  1. 哈希值的最高 \(k-1\) 位均为 0（连续 \(k-1\) 次反面）；
  2. 第 \(k\) 位为 1（第 \(k\) 次正面）。
- 由于每个比特独立且概率为 \(\frac{1}{2}\)，因此：
  \[
  P(\rho(s) = k) = \left(\frac{1}{2}\right)^{k-1} \cdot \frac{1}{2} = \left(\frac{1}{2}\right)^k
  \]
- 通俗解释：连续抛 \(k-1\) 次反面再抛 1 次正面的概率，符合几何分布（首次成功的试验次数分布）。

### 步骤 2：分桶策略——降低随机误差（论文 Section 1）

论文指出，仅统计单个元素的 \(\rho(s)\) 最大值（如早期的 Flajolet-Martin 算法）误差过大，因此引入“分桶平均”策略：

1. **分桶逻辑**：将哈希值的前 \(b\) 位作为“桶索引”，共划分 \(m = 2^b\) 个桶（论文推荐 \(m \geq 16\)，工程中常用 \(m=1024\) 或 \(m=2048\)）；
2. **桶内统计**：对每个元素，计算其桶索引 \(j\)（前 \(b\) 位）和剩余比特串的 \(\rho(s)\)，并更新第 \(j\) 个桶的最大值 \(M[j] = \max(M[j], \rho(s))\)；
3. **核心直觉**：数据集基数 \(n\) 越大，每个桶中“最长前导零长度 \(M[j]\)”越长——因为桶内元素数约为 \(n/m\)，元素数越多，出现“连续多次反面”的概率越高。

### 步骤 3：基数估算的核心公式推导（论文 Section 1-2）

论文的核心是通过“桶最大值的调和平均”反推基数，分为 3 个关键环节：

#### 环节 3.1：桶最大值与基数的关联

设每个桶内有 \(\nu \approx n/m\) 个元素（\(\nu\) 为桶内元素数），桶最大值 \(M[j]\) 的期望 \(E[M[j]]\) 与 \(\nu\) 满足：

- 对任意固定 \(k\)，“桶内所有元素的 \(\rho(s) < k\)”的概率为：
  \[
  P(M[j] < k) = \left[1 - P(\rho(s) \geq k)\right]^\nu
  \]
- 其中 \(P(\rho(s) \geq k) = \sum_{i=k}^\infty P(\rho(s)=i) = \left(\frac{1}{2}\right)^{k-1}\)（等比数列求和）；
- 当 \(n\) 较大时，用近似公式 \((1 - a/\nu)^\nu \approx e^{-a}\)，令 \(a = \nu / 2^{k-1}\)，则：
  \[
  P(M[j] < k) \approx e^{-\nu / 2^{k-1}}
  \]
- 当 \(P(M[j] < k) \approx 1/2\) 时，\(k\) 是 \(M[j]\) 的最可能值，此时 \(e^{-\nu / 2^{k-1}} \approx 1/2\)，解得：
  \[
  \nu \approx 2^{k-1} \cdot \log 2 \implies k \approx \log_2 \nu + 1
  \]
- 即 \(E[M[j]] \approx \log_2 (n/m) + 1\)，变形得 \(n \approx m \cdot 2^{E[M[j]] - 1}\)——这是基数估算的雏形。

#### 环节 3.2：调和平均优化（论文核心创新）

早期的 LogLog 算法用“算术平均”（\(\frac{1}{m}\sum 2^{M[j]}\)）估算 \(\nu\)，但论文指出“算术平均对极端值敏感”，因此改用**调和平均**（降低方差）：

- 调和平均定义：对桶最大值的函数 \(2^{-M[j]}\) 求和后取倒数，即：
  \[
  Z = \left( \sum_{j=1}^m 2^{-M[j]} \right)^{-1}
  \]
- 论文证明（Section 2.2）：调和平均 \(Z/m\) 的期望近似等于 \(\nu = n/m\)，即 \(E[Z/m] \approx n/m\)，因此 \(E[Z] \approx n\)。

#### 环节 3.3：修正系数 \(\alpha_m\) 的引入

由于哈希分布并非理想均匀、桶数 \(m\) 有限，直接用 \(Z\) 估算 \(n\) 存在系统性偏差，论文引入修正系数 \(\alpha_m\)（Section 1）：
\[
\alpha_m = \left( m \int_0^\infty \left( \log_2 \frac{2+u}{1+u} \right)^m du \right)^{-1}
\]

- 论文通过积分计算和实验拟合，给出工程可用的 \(\alpha_m\) 取值（Section 4）：
  | 桶数 \(m\) | 修正系数 \(\alpha_m\) |
  |------------|-----------------------|
  | 16         | 0.673                 |
  | 32         | 0.697                 |
  | 64         | 0.709                 |
  | \(m \geq 128\) | \(0.7213 / (1 + 1.079/m)\) |

#### 环节 3.4：最终基础估算公式

结合调和平均和修正系数，论文得到基数的基础估算公式（Section 1）：
\[
\hat{n} = \alpha_m \cdot m^2 \cdot Z = \alpha_m \cdot \frac{m^2}{\sum_{j=1}^m 2^{-M[j]}}
\]

- 通俗解释：\(\alpha_m\) 补偿偏差，\(m^2\) 是“桶数×桶内元素数估算”的乘积，分母是调和平均的核心项。

### 步骤 4：小基数与大基数的修正（论文 Section 4）

论文指出，基础公式在 \(n\) 过小时（\(n < 5m/2\)）或过大时（接近哈希位数上限）误差较大，需补充修正：

#### 修正 1：小基数修正（\(\hat{n} \leq 5m/2\)）

当基数较小时，部分桶可能未被更新（\(M[j] = 0\)），论文利用“空桶数 \(V\)”（\(M[j] = 0\) 的桶数）修正：

- 原理：\(n\) 较小时，空桶数 \(V \approx m \cdot e^{-n/m}\)（随机分配模型），变形得：
  \[
  \hat{n} = m \cdot \log\left( \frac{m}{V} \right)
  \]
- 论文验证：该修正能将小基数场景的误差从 30% 降至 5% 以内。

#### 修正 2：大基数修正（\(\hat{n} > 2^{32}\)）

当基数接近 32 位哈希的上限 \(2^{32}\) 时，哈希碰撞概率增加，论文引入对数修正：
\[
\hat{n} = -2^{32} \cdot \log\left( 1 - \frac{\hat{n}}{2^{32}} \right)
\]

- 原理：碰撞导致“哈希值去重后的个数”小于实际基数，通过对数逆运算补偿碰撞影响。

### 步骤 5：方差分析与误差边界（论文 Section 3）

论文通过“泊松化+去泊松化”（Section 2.3）分析估算值的方差，核心结论：

- 标准误差（相对误差）为 \(\sigma \approx \frac{\beta_m}{\sqrt{m}}\)，其中 \(\beta_\infty = \sqrt{3\log 2 - 1} \approx 1.03896\)；
- 工程中常用 \(m=1024\)，此时标准误差约为 \(1.04/\sqrt{1024} \approx 3.25\%\)，经 \(\alpha_m\) 修正后约 2%；
- 误差服从正态分布：65% 的估算值落在真实值的 \(\pm\sigma\) 内，95% 落在 \(\pm2\sigma\) 内，99% 落在 \(\pm3\sigma\) 内。

## 经典参考文献与论文

1. **Flajolet, P., Fusy, E., Gandouet, O., & Meunier, F. (2007). HyperLogLog: the analysis of a near-optimal cardinality estimation algorithm.**  
   - 核心贡献：提出 HyperLogLog 算法，优化 LogLog 的误差率，给出数学推导和实验验证，是该领域的奠基性论文。
2. **Flajolet, P., & Martin, G. N. (1984). Probabilistic counting algorithms for data base applications.**  
   - 核心贡献：提出“概率计数”的核心思想（LogLog/HLL 的前身），首次用前导零长度估算基数。
3. **Durand, M., & Flajolet, P. (2003). LogLog counting of large cardinalities.**  
   - 核心贡献：提出 LogLog 算法，通过分桶平均降低误差，为 HLL 奠定基础。
4. **Heule, S., Nunkesser, M., & Hall, A. (2013). HyperLogLog in practice: Algorithmic engineering of a state of the art cardinality estimation algorithm.**  
   - 核心贡献：优化 HLL 的小基数估算精度，提出偏差修正方法，被 Redis、ClickHouse 等工程实现采用。
5. **Redis 官方文档：HyperLogLog**  
   - 链接：https://redis.io/docs/data-types/probabilistic/hyperloglog/  
   - 价值：详细介绍 Redis 中 HLL 的实现细节、内存优化（如稀疏存储）和使用场景。
6. **ClickHouse 文档：Aggregate Functions - approx_count_distinct**  
   - 链接：https://clickhouse.com/docs/en/sql-reference/aggregate-functions/reference/approxcountdistinct/  
   - 价值：介绍 HLL 在列式数据库中的优化（如预聚合、压缩存储）。
