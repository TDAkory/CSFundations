# [HyperLogLog](https://en.wikipedia.org/wiki/HyperLogLog)

## 一、算法核心定位

**HyperLogLog（HLL）** 是由Philippe Flajolet等人于2007年提出的一种**近似基数计数算法**，核心目标是用极小的内存开销（空间复杂度仅为\(O(\log\log N)\)，N为数据集基数）估算大规模数据集的**基数（Cardinality，即不重复元素个数）** ；其原理基于“均匀分布哈希值的前导零长度统计”，通过分桶策略（通常划分为\(2^{10}=1024\)个桶）和调和平均降低误差，默认误差率约**2%** ，支持分布式场景下的结构合并，广泛应用于Redis、数据库（如PostgreSQL）的UV统计、日志去重等大规模数据计数场景，是“空间-精度”权衡的经典方案。

| 项目                | 关键内容                                                                 |
|---------------------|--------------------------------------------------------------------------|
| **算法名称**        | HyperLogLog（简称HLL）                                                  |
| **提出时间**        | 2007年                                                                   |
| **提出者**          | Philippe Flajolet、Éric Fusy、Olivier Gandouet、Frédéric Meunier          |
| **算法定位**        | 近似基数计数算法（估算数据集不重复元素个数）                             |
| **核心优势**        | 1. 空间开销极小：\(O(\log\log N)\)，1024个桶仅需1KB内存；2. 误差可控：默认约2%；3. 支持分布式合并 |
| **核心局限**        | 1. 仅近似计数，无法提供精确值；2. 不支持元素删除；3. 依赖高质量哈希函数（如MurmurHash） |

## 算法原理

### 基本原理

- **哈希均匀分布假设**：对数据集中每个元素应用64位哈希函数（如MurmurHash3、CityHash），得到均匀分布的二进制哈希值，确保每个bit为0或1的概率均为1/2。
- **前导零长度定义**：对任意元素的哈希值，定义\(ρ(x)\)为“从最低位开始连续的0的个数”，例如：
  - 哈希值`...0001`的\(ρ(x)=3\)；
  - 哈希值`...1`的\(ρ(x)=0\)；
- **概率关联**：数据集基数N越大，哈希值中“前导零长度较大”的元素越可能出现，例如N=10⁶时，大概率存在\(ρ(x)≥20\)的元素。

### 分桶优化（降低误差）

- **分桶策略**：将哈希值的前\(b\)位作为“桶索引”，剩余\(64-b\)位用于计算前导零长度\(ρ(x)\)，共划分\(m=2^b\)个桶（Wikipedia中典型取值为\(b=10\)，即\(m=1024\)个桶）。
- **桶内更新**：对每个元素，计算其桶索引\(i\)和\(ρ(x)\)，更新第\(i\)个桶的最大值\(M[i] = \max(M[i], ρ(x))\)（\(M[i]\)表示第\(i\)个桶中所有元素的最大前导零长度）。

### 基数估算公式

- **基础估算公式**：通过桶最大值的调和平均降低随机误差，公式如下：  
  \[
  \hat{n} = \alpha_m \cdot m \cdot \left( \sum_{i=0}^{m-1} \frac{1}{2^{M[i]}} \right)^{-1}
  \]  
  其中\(\alpha_m\)为**修正系数**，用于补偿哈希非理想分布和有限桶数的偏差，取值随桶数\(m\)变化：
  | 桶数\(m\) | 修正系数\(\alpha_m\) |
  |-----------|----------------------|
  | 16        | 0.673                |
  | 32        | 0.697                |
  | 64        | 0.709                |
  | ≥128      | 0.7213/(1+1.079/m)    |
- **小基数修正**：当估算值\(\hat{n} < 5m\)时，直接统计“未更新的桶数\(V_0\)（即\(M[i]=0\)的桶数）”，用以下公式修正，提升小数据集估算精度：  
  \[
  \hat{n} = m \cdot \log\left( \frac{m}{V_0} \right)
  \]
- **大基数截断**：当估算值超过哈希值位数对应的最大基数（如64位哈希的最大基数\(2^{64}\)）时，直接截断为最大值，避免溢出。

### 典型应用场景

| 场景领域       | 具体应用案例                                                                 | 核心优势体现                     |
|----------------|------------------------------------------------------------------------------|----------------------------------|
| 互联网UV统计   | 网站/APP的日活（DAU）、月活（MAU）统计，如1亿用户仅需1KB内存存储HLL结构       | 空间效率极高，降低服务器内存占用 |
| 数据库查询优化 | PostgreSQL、ClickHouse等数据库的`APPROX_COUNT_DISTINCT`函数，加速去重计数查询 | 避免全表扫描，提升查询性能       |
| 缓存系统       | Redis内置`PFADD`（插入元素）、`PFCOUNT`（估算基数）、`PFMERGE`（合并结构）命令 | 支持分布式计数，适配缓存场景     |
| 日志分析       | Nginx日志中独立IP、独立请求URL的计数，处理TB级日志数据                         | 处理大规模数据，无需存储原始数据 |

## 延伸问题

### 问题1：HyperLogLog算法为什么能实现“极小内存开销”？其空间复杂度\(O(\log\log N)\)是如何推导的？

**答案**：  
- 核心原因：HLL不存储原始元素，仅存储“分桶后的最大前导零长度”——每个桶仅需1个整数（通常4字节）记录最大值，桶数\(m=2^b\)（b为哈希值用于桶索引的位数），而b的取值仅需随\(\log\log N\)增长（例如N=10¹²时，b=12即可满足误差要求），因此总内存开销为\(O(m)=O(2^b)=O(\log\log N)\)。  
- 推导逻辑：假设数据集基数为N，哈希值前导零长度的最大值\(ρ_{max}\)满足\(2^{ρ_{max}} ≈ N\)（概率意义上），即\(ρ_{max} ≈ \log_2 N\)；分桶数m需与\(ρ_{max}\)成正比（确保误差可控），即\(m ∝ \log_2 N\)，但实际工程中m取\(2^b\)，b仅需\(\log_2(\log_2 N)\)（例如N=10¹²时，\(\log_2 N≈40\)，\(\log_2(\log_2 N)≈6\)，实际取b=10即可），因此空间复杂度最终为\(O(\log\log N)\)。

### 问题2：HyperLogLog的误差率如何控制？在实际工程中（如Redis），若需将误差率从2%降至1%，需如何调整参数？
**答案**：  
- 误差控制原理：HLL的误差主要来自“哈希分布偏差”和“分桶统计的随机波动”，通过两个机制控制：1. 分桶策略（增加桶数m，降低随机波动）；2. 修正系数\(\alpha_m\)（补偿哈希非均匀分布的偏差），理论误差率公式为\(\epsilon ≈ 1.04/\sqrt{m}\)。  
- 工程参数调整：  
  - 默认误差率2%：对应桶数\(m=1024\)（\(1.04/\sqrt{1024}≈1.04/32≈3.25\%\)，实际通过\(\alpha_m\)修正后约2%）；  
  - 误差率降至1%：根据\(\epsilon ≈ 1.04/\sqrt{m}\)，解得\(m≈(1.04/0.01)^2≈10816\)，取\(m=16384\)（\(2^{14}\)），此时\(1.04/\sqrt{16384}≈1.04/128≈0.81\%\)，满足1%误差要求；  
  - Redis中的实现：Redis默认使用m=1024（误差约2%），若需更低误差，需通过自定义参数调整桶数（需注意内存开销同步增加，m=16384时内存开销约16KB）。

### 问题3：HyperLogLog支持分布式场景的合并操作，其合并原理是什么？与其他分布式基数计数方案（如布隆过滤器+哈希表）相比，HLL的优势在哪里？
**答案**：  
- 合并原理：HLL的合并逻辑基于“逐桶取最大值”——两个HLL结构（需保证桶数m相同）合并时，对每个桶索引i，新桶的最大值\(M_{merged}[i] = \max(M_1[i], M_2[i])\)，合并后的结构可直接用于\(PFCOUNT\)估算总基数；该过程无需汇总原始数据，仅需传输HLL的桶数组（如m=1024时仅需1KB数据），适合分布式场景。  
- 与其他方案的优势对比：  
  | 对比维度       | HyperLogLog                | 布隆过滤器+哈希表            |
  |----------------|-----------------------------|-------------------------------|
  | 空间开销       | 极小（数KB）                | 较大（布隆过滤器+哈希表存储） |
  | 合并复杂度     | 低（逐桶取最大值，O(m)时间） | 高（需合并哈希表，O(N)时间） |
  | 误差特性       | 可控（2%/1%）               | 无误差（精确计数）            |
  | 适用场景       | 大规模近似计数（如UV）       | 小规模精确计数（如小数据集去重） |
  - 核心优势：HLL在“大规模分布式场景”下，空间开销和合并效率远优于布隆过滤器+哈希表，虽为近似计数，但误差可控，能满足绝大多数工程场景（如UV统计无需精确到个位数）的需求。


## 二、核心原理
### 2.1 基础思想：伯努利试验与位模式统计
HLL 的核心灵感来自**伯努利试验**和**二进制位串的概率特性**：
1. **伯努利试验类比**：对数据集的每个元素做哈希（如 MurmurHash），得到一个 64 位随机二进制串（哈希值均匀分布）。将“哈希值的二进制表示”视为伯努利试验序列——“0”代表失败，“1”代表成功。
2. **关键观察**：对于均匀分布的哈希值，一个元素的哈希值中，**从最低位开始连续的 0 的个数（记为“前导零长度”，用 \(ρ(x)\) 表示）** 服从几何分布。例如：
   - 哈希值 `...0001` 的前导零长度 \(ρ=3\)；
   - 哈希值 `...1` 的前导零长度 \(ρ=0\)；
   - 哈希值 `...0010` 的前导零长度 \(ρ=2\)。
3. **基数估算逻辑**：对于基数为 \(n\) 的数据集，哈希值中“最大前导零长度”（记为 \(ρ_{max}\)）与 \(n\) 满足对数关系——数据集越大，越可能出现“更长的连续前导零”。例如：
   - 若 \(n=1000\)，大概率存在一个元素的哈希值前导零长度 \(ρ≥10\)；
   - 若 \(n=10^6\)，大概率存在一个元素的哈希值前导零长度 \(ρ≥20\)。

### 2.2 分桶优化（LogLog 核心改进）
原始“单桶”估算（仅统计全局最大前导零长度）误差较大，LogLog 算法通过**分桶平均**降低误差：
1. **分桶策略**：将哈希值的前 \(b\) 位作为“桶索引”，剩余 \(L\) 位（如 \(L=64-b\)）用于计算前导零长度 \(ρ\)。共划分 \(m=2^b\) 个桶（通常 \(b=10\)，即 \(m=1024\) 个桶）。
2. **桶内统计**：对每个元素，计算其哈希值的桶索引 \(i\) 和对应前导零长度 \(ρ\)，并更新第 \(i\) 个桶的最大值 \(M[i] = \max(M[i], ρ)\)。
3. **估算公式**：通过桶最大值的调和平均降低随机误差，LogLog 估算公式为：
   \[
   \hat{n} = \alpha_m \cdot m^2 \cdot \left( \sum_{i=0}^{m-1} \frac{1}{2^{M[i]}} \right)^{-1}
   \]
   其中 \(\alpha_m\) 是修正系数（与桶数 \(m\) 相关，用于补偿哈希分布偏差）。

### 2.3 HyperLogLog 的关键优化
HLL 在 LogLog 基础上引入**调和平均替代算术平均**，进一步降低误差：
- LogLog 用算术平均：\(\frac{1}{m} \sum_{i=0}^{m-1} 2^{M[i]}\)（对异常值敏感）；
- HLL 用调和平均：\(\left( \frac{1}{m} \sum_{i=0}^{m-1} \frac{1}{2^{M[i]}} \right)^{-1}\)（对极端值更稳健）。

最终 HLL 基数估算公式为：
\[
\hat{n} = \alpha_m \cdot m \cdot \left( \sum_{i=0}^{m-1} \frac{1}{2^{M[i]}} \right)^{-1}
\]

### 2.4 偏差修正（提高小基数估算精度）
当数据集基数较小时（如 \(n < 5m\)），上述公式误差较大，需通过**小范围修正**和**阈值截断**优化：
1. 若估算值 \(\hat{n} < 5m\)，直接统计“未更新的桶数（\(V_0\)，即 \(M[i]=0\) 的桶数）”，用以下公式修正：
   \[
   \hat{n} = m \cdot \log\left( \frac{m}{V_0} \right)
   \]
2. 若估算值超出哈希值位数对应的最大可能基数（如 64 位哈希的最大基数 \(2^{64}\)），直接截断为最大值。


## 三、数学推导
### 3.1 前导零长度的概率分布
设哈希函数均匀分布，哈希值的每一位独立且为 0 或 1 的概率均为 \(1/2\)。对于任意元素，其前导零长度 \(ρ(x) = k\) 的概率为：
- 前 \(k\) 位均为 0，第 \(k+1\) 位为 1；
- 概率：\(P(ρ(x)=k) = \left(\frac{1}{2}\right)^k \cdot \frac{1}{2} = \left(\frac{1}{2}\right)^{k+1}\)。

### 3.2 桶最大值的期望与基数关系
对于 \(m\) 个桶，每个桶的最大值 \(M[i]\) 的期望 \(E[M[i]]\) 与数据集基数 \(n\) 满足：
- 对于单个桶，“没有元素的前导零长度 ≥ k”的概率为 \(\left(1 - \frac{1}{2^k}\right)^n\)；
- 桶最大值 \(M[i] < k\) 的概率为 \(\left(1 - \frac{1}{2^k}\right)^n\)；
- 桶最大值 \(M[i] = k\) 的概率为 \(\left(1 - \frac{1}{2^k}\right)^n - \left(1 - \frac{1}{2^{k+1}}\right)^n\)；
- 期望 \(E[M[i]] = \sum_{k=0}^{\infty} P(M[i] ≥ k) = \sum_{k=0}^{\infty} \left[1 - \left(1 - \frac{1}{2^k}\right)^n\right]\)。

当 \(n\) 较大时，\(\left(1 - \frac{1}{2^k}\right)^n \approx e^{-n/2^k}\)，代入得：
\[
E[M[i]] \approx \sum_{k=0}^{\infty} \left(1 - e^{-n/2^k}\right)
\]

### 3.3 调和平均与基数估算
HLL 用 \(\sum_{i=0}^{m-1} \frac{1}{2^{M[i]}}\) 的调和平均估算基数。根据大数定律，当 \(m\) 足够大时：
\[
\frac{1}{m} \sum_{i=0}^{m-1} \frac{1}{2^{M[i]}} \approx E\left[ \frac{1}{2^{M[i]}} \right]
\]

通过积分近似计算期望 \(E\left[ \frac{1}{2^{M[i]}} \right] = \frac{1}{n} \cdot \ln 2\)（推导略），代入得：
\[
\frac{1}{m} \cdot \frac{1}{E\left[ \frac{1}{2^{M[i]}} \right]} \approx \frac{n}{\ln 2}
\]

引入修正系数 \(\alpha_m\) 补偿哈希非理想分布和有限桶数的偏差，最终得到估算公式：
\[
\hat{n} = \alpha_m \cdot m \cdot \left( \sum_{i=0}^{m-1} \frac{1}{2^{M[i]}} \right)^{-1}
\]

### 3.4 修正系数 \(\alpha_m\) 的取值
\(\alpha_m\) 是与桶数 \(m\) 相关的常数，由实验拟合得到：
- 当 \(m=16\) 时，\(\alpha_m = 0.673\)；
- 当 \(m=32\) 时，\(\alpha_m = 0.697\)；
- 当 \(m=64\) 时，\(\alpha_m = 0.709\)；
- 当 \(m≥128\) 时，\(\alpha_m = 0.7213 / (1 + 1.079/m)\)。


## 四、伪代码实现
### 4.1 核心数据结构
- `m`：桶数（通常取 \(2^{10}=1024\)，\(b=10\) 位桶索引）；
- `M`：桶数组，长度为 `m`，存储每个桶的最大前导零长度（初始值为 0）；
- `hash_func`：64 位哈希函数（如 MurmurHash3、CityHash）；
- `alpha_m`：修正系数（根据 `m` 计算）。

### 4.2 插入元素（Add）
```plaintext
function Add(element):
    hash_val = hash_func(element)  // 64 位哈希值（二进制串）
    // 1. 取前 b 位作为桶索引 i（b = log2(m)）
    b = log2(m)
    i = hash_val >> (64 - b)  // 右移 64-b 位，取高 b 位
    // 2. 取剩余 64-b 位，计算前导零长度 ρ
    remaining_bits = hash_val & ((1 << (64 - b)) - 1)  // 低 64-b 位
    rho = 0
    while remaining_bits != 0 and (remaining_bits & 1) == 0:
        rho += 1
        remaining_bits >>= 1
    // 3. 更新桶 i 的最大值
    if rho > M[i]:
        M[i] = rho
```

### 4.3 估算基数（Count）
```plaintext
function Count():
    // 1. 计算调和和
    harmonic_sum = 0.0
    V0 = 0  // 未更新的桶数（M[i] == 0）
    for i from 0 to m-1:
        if M[i] == 0:
            V0 += 1
        harmonic_sum += 1.0 / (1 << M[i])  // 1/(2^M[i])
    // 2. 基础估算
    alpha_m = 0.7213 / (1 + 1.079/m)  // m ≥ 128 时
    estimator = alpha_m * m / harmonic_sum
    // 3. 小基数修正
    if estimator < 5 * m:
        estimator = m * log(m / V0)  // 自然对数
    // 4. 大基数截断（64 位哈希最大值）
    max_cardinality = 1 << 64
    if estimator > max_cardinality:
        estimator = max_cardinality
    return floor(estimator)
```

### 4.4 合并两个 HLL 结构（Merge）
HLL 支持分布式场景的并行计数，合并逻辑为“逐桶取最大值”：
```plaintext
function Merge(hll1, hll2):
    if hll1.m != hll2.m:
        throw Error("桶数必须一致")
    merged_hll = new HLL(m = hll1.m)
    for i from 0 to merged_hll.m - 1:
        merged_hll.M[i] = max(hll1.M[i], hll2.M[i])
    return merged_hll
```


## 五、典型应用场景
HLL 因“低内存、支持合并、误差可控”的特性，广泛应用于大规模数据场景：
### 5.1 互联网核心场景
1. **UV 统计**：网站/APP 的日活（DAU）、月活（MAU）统计（如亿级用户仅需 1KB 内存）；
2. **去重计数**：搜索引擎关键词去重、广告点击量去重、日志系统中的独立 IP/设备计数；
3. **分布式计数**：大数据平台（Hadoop、Spark）的并行基数估算（各节点独立计数，最终合并 HLL 结构）。

### 5.2 数据库与缓存
1. **Redis 基数统计**：Redis 内置 `PFADD`（插入）、`PFCOUNT`（估算）、`PFMERGE`（合并）命令，基于 HLL 实现；
2. **SQL 近似查询**：PostgreSQL、ClickHouse 等数据库支持 `APPROX_COUNT_DISTINCT` 函数，底层基于 HLL 优化查询性能。

### 5.3 监控与日志分析
1. **流量监控**：统计一段时间内独立访问的 IP 数、接口调用的独立用户数；
2. **日志去重**：大规模日志（如 Nginx 日志）中的独立请求 URL、独立客户端 ID 计数。


## 经典参考文献与论文

1. **Flajolet, P., Fusy, E., Gandouet, O., & Meunier, F. (2007). HyperLogLog: the analysis of a near-optimal cardinality estimation algorithm.**  
   - 核心贡献：提出 HyperLogLog 算法，优化 LogLog 的误差率，给出数学推导和实验验证，是该领域的奠基性论文。
2. **Flajolet, P., & Martin, G. N. (1984). Probabilistic counting algorithms for data base applications.**  
   - 核心贡献：提出“概率计数”的核心思想（LogLog/HLL 的前身），首次用前导零长度估算基数。
3. **Durand, M., & Flajolet, P. (2003). LogLog counting of large cardinalities.**  
   - 核心贡献：提出 LogLog 算法，通过分桶平均降低误差，为 HLL 奠定基础。
4. **Heule, S., Nunkesser, M., & Hall, A. (2013). HyperLogLog in practice: Algorithmic engineering of a state of the art cardinality estimation algorithm.**  
   - 核心贡献：优化 HLL 的小基数估算精度，提出偏差修正方法，被 Redis、ClickHouse 等工程实现采用。
5. **Redis 官方文档：HyperLogLog**  
   - 链接：https://redis.io/docs/data-types/probabilistic/hyperloglog/  
   - 价值：详细介绍 Redis 中 HLL 的实现细节、内存优化（如稀疏存储）和使用场景。
6. **ClickHouse 文档：Aggregate Functions - approx_count_distinct**  
   - 链接：https://clickhouse.com/docs/en/sql-reference/aggregate-functions/reference/approxcountdistinct/  
   - 价值：介绍 HLL 在列式数据库中的优化（如预聚合、压缩存储）。
